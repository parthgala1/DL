{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad69f4fd-2bf0-4c62-bdc6-dc5b82a44ceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (947603589.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython3.10 -m venv tf-env\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b11247df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cf73b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exp 1- 8 as per executed in labs Inputs will be varied practicals hard coded , some with tensorflow and keras CNN, rnn, autoencoder and backpropogation can be implemented on datasets mostly mnist, iris, catand dog Sometimes u need to take inputs of dataset by creating shapes So there are variations while taking inputs Instructions while coming to the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168853d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d070f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Delta_b:  [-1, 0, 0, 1] Final Weights:  [1, 1] Final Bias:  0\n",
      "Epoch:  2 Delta_b:  [-1, -1, 0, 1] Final Weights:  [1, 2] Final Bias:  -1\n",
      "Epoch:  3 Delta_b:  [0, -1, -1, 1] Final Weights:  [1, 2] Final Bias:  -2\n",
      "Epoch:  4 Delta_b:  [0, 0, -1, 1] Final Weights:  [2, 2] Final Bias:  -2\n",
      "Epoch:  5 Delta_b:  [0, -1, 0, 0] Final Weights:  [1, 2] Final Bias:  -3\n",
      "Epoch:  6 Delta_b:  [0, 0, 0, 0] Final Weights:  [1, 2] Final Bias:  -3\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Perceptron Learning Algorithm\n",
    "\n",
    "def bipolar(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def unipolar(net):\n",
    "    if net < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def process(x, d, w1, w2, b, activation, delta_b, c=1):\n",
    "    net = w1*x[0] + w2*x[1] + b\n",
    "    fnet = activation(net)\n",
    "    error = d - fnet\n",
    "    del_w1 = c * error * x[0]\n",
    "    del_w2 = c * error * x[1]\n",
    "    del_b = error\n",
    "    delta_b.append(del_b)\n",
    "    w1 += del_w1\n",
    "    w2 += del_w2\n",
    "    b += del_b\n",
    "    return w1, w2, b, delta_b\n",
    "\n",
    "x = [[0, 0], \n",
    "     [1, 0],\n",
    "     [0, 1],\n",
    "     [1, 1]]\n",
    "d = [0, 0, 0, 1]\n",
    "w1, w2, b = 0, 0, 0\n",
    "epoch = 0\n",
    "delta_b = []\n",
    "while delta_b != [0, 0, 0, 0]:\n",
    "    epoch += 1\n",
    "    delta_b = []\n",
    "    for i in range(len(x)):\n",
    "        w1, w2, b, delta_b = process(x[i], d[i], w1, w2, b, unipolar, delta_b)\n",
    "\n",
    "    print(\"Epoch: \", epoch, \"Delta_b: \", delta_b, \"Final Weights: \", [w1, w2], \"Final Bias: \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068374f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782644e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Experiment 2: Packpropagation Algorithm\n",
    "# Forward and Backward Pass\n",
    "\n",
    "# 0 - 0 - 0\n",
    "# 0 - 0 - 0\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def forward_pass(input, weight, bias, activation):\n",
    "    layer = np.dot(weight, input) + bias\n",
    "    return float(activation(layer)[0])\n",
    "\n",
    "def error_calculation(excepted_output, output):\n",
    "    return 0.5 * np.sum((excepted_output - output) ** 2)\n",
    "\n",
    "def update_weights_inner(output, target, hidden, input, weight_affecting, weight_i, learning_rate):\n",
    "    error_i_1 = (output[0] - target[0]) * (output[0] * (1 - output[0])) * weight_affecting[0] * (hidden[0] * (1 - hidden[0])) * input\n",
    "    error_i_2 = (output[1] - target[1]) * (output[1] * (1 - output[1])) * weight_affecting[1] * (hidden[0] * (1 - hidden[0])) * input\n",
    "    error_i = error_i_1 + error_i_2\n",
    "    weight = weight_i - learning_rate * error_i\n",
    "    return weight\n",
    "\n",
    "def update_weights_outer(output, target, input, weight_i, learning_rate):\n",
    "    error_i = (output - target) * (output * (1 - output)) * input\n",
    "    weight = weight_i - learning_rate * error_i\n",
    "    return weight\n",
    "\n",
    "def backward_pass(weights, biases, inputs, hidden, excepted_output, output):\n",
    "    w5 = update_weights_outer(output[0], excepted_output[0], hidden[0], weights[4], 0.6)\n",
    "    w6 = update_weights_outer(output[0], excepted_output[0], hidden[1], weights[5], 0.6)\n",
    "    w7 = update_weights_outer(output[1], excepted_output[1], hidden[1], weights[6], 0.6)\n",
    "    w8 = update_weights_outer(output[0], excepted_output[0], hidden[1], weights[7], 0.6)\n",
    "\n",
    "    w1 = update_weights_inner(output, excepted_output, hidden, inputs[0], [weights[4], weights[6]], weights[0], 0.6)\n",
    "    w2 = update_weights_inner(output, excepted_output, hidden, inputs[1], [weights[5], weights[7]], weights[2], 0.6)\n",
    "    w3 = update_weights_inner(output, excepted_output, hidden, inputs[0], [weights[4], weights[6]], weights[1], 0.6)\n",
    "    w4 = update_weights_inner(output, excepted_output, hidden, inputs[1], [weights[5], weights[7]], weights[3], 0.6)\n",
    "\n",
    "    return np.array([w1, w2, w3, w4, w5, w6, w7, w8])\n",
    "\n",
    "inputs = [0.1, 0.5]\n",
    "weights = [0.1, 0.3, 0.2, 0.4 , 0.5, 0.6, 0.7, 0.8]\n",
    "biases = [0.25, 0.25, 0.35, 0.35]\n",
    "excepted_output = [0.05, 0.95]\n",
    "\n",
    "hidden_network1 = forward_pass(inputs, weights[:2], biases[:1], sigmoid)\n",
    "hidden_network2 = forward_pass(inputs, weights[2:4], biases[1:2], sigmoid)\n",
    "hidden = [hidden_network1, hidden_network2]\n",
    "output_network1 = forward_pass(hidden, weights[4:6], biases[2:3], sigmoid)\n",
    "output_network2 = forward_pass(hidden, weights[6:8], biases[3:4], sigmoid)\n",
    "output = [output_network1, output_network2]\n",
    "\n",
    "error = error_calculation(np.array(excepted_output), np.array(output))\n",
    "\n",
    "# updated_weights = backward_pass(weights, biases, inputs, hidden, excepted_output, output)\n",
    "# print(\"Updated Weights: \", updated_weights)\n",
    "\n",
    "epochs = 47000\n",
    "\n",
    "for i in range(epochs):\n",
    "    hidden_network1 = forward_pass(inputs, weights[:2], biases[:1], sigmoid)\n",
    "    hidden_network2 = forward_pass(inputs, weights[2:4], biases[1:2], sigmoid)\n",
    "    hidden = [hidden_network1, hidden_network2]\n",
    "    output_network1 = forward_pass(hidden, weights[4:6], biases[2:3], sigmoid)\n",
    "    output_network2 = forward_pass(hidden, weights[6:8], biases[3:4], sigmoid)\n",
    "    output = [output_network1, output_network2]\n",
    "\n",
    "    error = error_calculation(np.array(excepted_output), np.array(output))\n",
    "\n",
    "    updated_weights = backward_pass(updated_weights, biases, inputs, hidden, excepted_output, output)\n",
    "    weights = updated_weights\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Epoch {i}: Error: {error}\")\n",
    "    if error < 0.01:\n",
    "        break\n",
    "print(\"Final Output: \", output)\n",
    "print(\"Final Weights: \", weights)\n",
    "print(\"Final Error: \", error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0e903",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04adbd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3: CNN\n",
    "\n",
    "def convolve2d(image, kernel, stride):\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    image_height, image_width = image.shape\n",
    "    output_height = (image_height - kernel_height) // stride + 1\n",
    "    output_width = (image_width - kernel_width) // stride + 1\n",
    "    new_image = np.zeros((output_height, output_width)).astype(np.int32)\n",
    "    for x in range(0, output_width):\n",
    "        for y in range(0, output_height):\n",
    "            new_image[y][x] = np.sum(image[y * stride:y * stride + kernel_height, x * stride:x * stride + kernel_width] * kernel).astype(np.int32)\n",
    "    return new_image\n",
    "\n",
    "def maxpooling(input, pool_size, stride):\n",
    "    input_height, input_width = input.shape\n",
    "    output_height = (input_height - pool_size) // stride + 1\n",
    "    output_width = (input_width - pool_size) // stride + 1\n",
    "    new_image = np.zeros((output_height, output_width)).astype(np.int32)\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            new_image[i, j] = np.max(input[i:i + pool_size, j:j + pool_size])\n",
    "    return new_image.astype(np.int32)\n",
    "\n",
    "\n",
    "def flatten(input):\n",
    "    return input.flatten()\n",
    "\n",
    "def dense(input, weights, bias):\n",
    "    return np.dot(weights, input) + bias\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1 / (1 + np.exp(-x)))\n",
    "\n",
    "def train_cnn(input, kernel, pool_size, stride):\n",
    "    conv_output = convolve2d(input, kernel, stride)\n",
    "    relu_output = relu(conv_output)\n",
    "    print(\"Convolution Output: \\n\", relu_output)\n",
    "    plt.imshow(relu_output, cmap='gray')\n",
    "    plt.title(\"Convolution Output\")\n",
    "    plt.show()\n",
    "\n",
    "    pool_output = maxpooling(relu_output, pool_size, stride)\n",
    "    print(\"Max Pooling Output: \\n\", pool_output)\n",
    "    plt.imshow(pool_output, cmap='gray')\n",
    "    plt.title(\"Max Pooling Output\")\n",
    "    plt.show()\n",
    "\n",
    "    flatten_output = flatten(pool_output)\n",
    "    print(\"Flatten Output: \\n\", flatten_output)\n",
    "    plt.imshow(flatten_output.reshape(1, -1), cmap='gray')\n",
    "    plt.title(\"Flatten Output\")\n",
    "    plt.show()\n",
    "\n",
    "    weights = np.random.rand(flatten_output.size)\n",
    "    bias = np.random.rand(1)\n",
    "    dense_output = dense(flatten_output, weights, bias)\n",
    "    print(\"Dense Layer Output: \\n\", dense_output)\n",
    "    plt.imshow(dense_output.reshape(1, -1), cmap='gray')\n",
    "    plt.title(\"Dense Layer Output\")\n",
    "    plt.show()\n",
    "\n",
    "    sigmoid_output = sigmoid(dense_output)\n",
    "    return sigmoid_output\n",
    "pool_size = 2\n",
    "stride = 1\n",
    "input = np.random.randint(0, 255, (9, 9)).astype(np.int32)\n",
    "kernel = np.array([[1, 3, 1], \n",
    "                   [2, 0, 0], \n",
    "                   [-1, 1, -2]])\n",
    "# [[-1, 0, 1],\n",
    "#  [-1, 0, 1],\n",
    "#  [-1, 0 ,1]]\n",
    "print(\"Input Image: \\n\", input)\n",
    "print(\"Kernel: \\n\", kernel)\n",
    "plt.imshow(input, cmap='gray')\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "sigmoid_output = train_cnn(input, kernel, pool_size, stride)\n",
    "print(\"sigmoid Output: \", sigmoid_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7637ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8997 - loss: 0.3275 - val_accuracy: 0.9788 - val_loss: 0.0741\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.0597 - val_accuracy: 0.9799 - val_loss: 0.0694\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.0339 - val_accuracy: 0.9848 - val_loss: 0.0518\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 0.0244 - val_accuracy: 0.9854 - val_loss: 0.0532\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0136 - val_accuracy: 0.9858 - val_loss: 0.0550\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9804 - loss: 0.0608\n",
      "Test accuracy: 0.9847999811172485\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "data = mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = data\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cb6b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">692,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m692,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,081,888</span> (7.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,081,888\u001b[0m (7.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,387,926</span> (5.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,387,926\u001b[0m (5.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "predicted_classes = np.argmax(y_pred, axis=1)\n",
    "print(\"Predicted classes: \", predicted_classes)\n",
    "print(\"True classes: \", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267eeca1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f405800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "RNN Output: \n",
      " [[0.99989174]\n",
      " [0.99992822]\n",
      " [0.99992822]\n",
      " [0.99992822]\n",
      " [0.99992822]]\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4: RNN\n",
    "\n",
    "input_sentences = [\n",
    "    \"I love programming\",\n",
    "    \"Python is great\",\n",
    "    \"I enjoy learning new things\",\n",
    "    \"TensorFlow is a powerful library\",\n",
    "    \"Deep learning is fascinating\"\n",
    "]\n",
    "\n",
    "def one_hot_encode(sentences):\n",
    "    tokens = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "    vocab = set(word for sentence in tokens for word in sentence)\n",
    "    print(len(vocab))\n",
    "    word_to_index = {word: i for i, word in enumerate(vocab)}\n",
    "    encoded = []\n",
    "    for sentence in tokens:\n",
    "        encoded_sentence = np.zeros(len(vocab))\n",
    "        for word in sentence:\n",
    "            encoded_sentence[word_to_index[word]] = 1\n",
    "        encoded.append(encoded_sentence)\n",
    "    return np.array(encoded)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def SimpleRNN(input):\n",
    "    embeddings = one_hot_encode(input)\n",
    "\n",
    "    input_size = embeddings.shape[1]\n",
    "    hidden_size = 20\n",
    "    output_size = 1\n",
    "    weights_input = np.random.rand(input_size, hidden_size)\n",
    "    weights_hidden = np.random.rand(hidden_size, hidden_size)\n",
    "    weights_output = np.random.rand(hidden_size, output_size)\n",
    "    biases_hidden = np.random.rand(hidden_size)\n",
    "    biases_output = np.random.rand(output_size)\n",
    "    hidden_state = np.zeros(hidden_size)\n",
    "    outputs = []\n",
    "\n",
    "    for t in embeddings:\n",
    "        hidden_state = np.tanh(np.dot(t, weights_input) + np.dot(hidden_state, weights_hidden) + biases_hidden)\n",
    "        output = sigmoid(np.dot(hidden_state, weights_output) + biases_output)\n",
    "        outputs.append(output)\n",
    "    return np.array(outputs)\n",
    "\n",
    "rnn_output = SimpleRNN(input_sentences)\n",
    "print(\"RNN Output: \\n\", rnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fea500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 60ms/step - accuracy: 0.5058 - loss: 0.6953 - val_accuracy: 0.5586 - val_loss: 0.6907\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5427 - loss: 0.6852"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "data = imdb.load_data(num_words=1000)\n",
    "(x_train, y_train),(x_test, y_test) = data\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "model.add(layers.SimpleRNN(128))\n",
    "model.add(layers.Dense(10, activation='sigmoid'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=500)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=500)\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810bae3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d831d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "predicted_classes = np.argmax(y_pred, axis=1)\n",
    "print(\"Predicted classes: \", predicted_classes)\n",
    "print(\"True classes: \", y_test)\n",
    "print(x_test[0], predicted_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91681df0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e840f8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.38)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distance(input, weights):\n",
    "    sum = 0\n",
    "    for i, w in zip(input, weights):\n",
    "        sum += np.pow(i - w, 2)\n",
    "    return sum\n",
    "\n",
    "def som(x, w):\n",
    "    min_dist = min(distance(x, w.T[0]), distance(x, w.T[1]))\n",
    "\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "x = [1, 0, 1, 0]\n",
    "w = np.array(\n",
    "    [[0.2, 0.8],\n",
    "     [0.6, 0.4],\n",
    "     [0.5, 0.7],\n",
    "     [0.9, 0.3]]\n",
    ")\n",
    "\n",
    "som(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f94359b2-3810-41ca-9559-999f9f56de77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.03754541 0.75417621]\n",
      "  [0.06243721 0.70862715]\n",
      "  [0.09151505 0.59479407]\n",
      "  [0.13316265 0.54653364]\n",
      "  [0.13951154 0.49315309]\n",
      "  [0.18195957 0.41418339]\n",
      "  [0.15103886 0.35789744]\n",
      "  [0.13525367 0.30800238]\n",
      "  [0.13368453 0.27206507]\n",
      "  [0.1034411  0.22077095]]\n",
      "\n",
      " [[0.06795013 0.81370199]\n",
      "  [0.06586271 0.7241955 ]\n",
      "  [0.11192073 0.66532842]\n",
      "  [0.15738638 0.57003077]\n",
      "  [0.22605298 0.50709606]\n",
      "  [0.20728046 0.43193992]\n",
      "  [0.25557086 0.36616791]\n",
      "  [0.18262342 0.28846613]\n",
      "  [0.14850224 0.2112611 ]\n",
      "  [0.13400217 0.18250384]]\n",
      "\n",
      " [[0.12506835 0.83333662]\n",
      "  [0.12108477 0.78646578]\n",
      "  [0.18720945 0.63083588]\n",
      "  [0.2603896  0.56811517]\n",
      "  [0.30120969 0.50363199]\n",
      "  [0.35540615 0.42206597]\n",
      "  [0.35840022 0.32758918]\n",
      "  [0.31639241 0.25682901]\n",
      "  [0.21422673 0.15694134]\n",
      "  [0.20756642 0.10922378]]\n",
      "\n",
      " [[0.17445615 0.8279782 ]\n",
      "  [0.25113351 0.76362549]\n",
      "  [0.28008676 0.65214336]\n",
      "  [0.35052004 0.56677479]\n",
      "  [0.37779209 0.46339596]\n",
      "  [0.43920733 0.40506416]\n",
      "  [0.42303317 0.33690224]\n",
      "  [0.38709743 0.27101099]\n",
      "  [0.34722475 0.17307241]\n",
      "  [0.26875508 0.07923619]]\n",
      "\n",
      " [[0.27555643 0.81103714]\n",
      "  [0.26499495 0.77590467]\n",
      "  [0.38345262 0.68410846]\n",
      "  [0.4118293  0.56269059]\n",
      "  [0.47654674 0.4813837 ]\n",
      "  [0.46959579 0.38507089]\n",
      "  [0.48116918 0.34966386]\n",
      "  [0.44665508 0.25559479]\n",
      "  [0.39287743 0.16866086]\n",
      "  [0.34058692 0.0982758 ]]\n",
      "\n",
      " [[0.34556099 0.82415608]\n",
      "  [0.42188797 0.73463214]\n",
      "  [0.48565068 0.66507535]\n",
      "  [0.51074232 0.58568979]\n",
      "  [0.53657713 0.49752157]\n",
      "  [0.56804135 0.42760508]\n",
      "  [0.51859825 0.33624823]\n",
      "  [0.55271073 0.28114338]\n",
      "  [0.48413777 0.15442586]\n",
      "  [0.49572677 0.04793499]]\n",
      "\n",
      " [[0.45965789 0.80277855]\n",
      "  [0.53972699 0.75902565]\n",
      "  [0.53690826 0.68966798]\n",
      "  [0.58295309 0.63801983]\n",
      "  [0.59264252 0.51995135]\n",
      "  [0.6210837  0.43701516]\n",
      "  [0.62348458 0.34811845]\n",
      "  [0.62941075 0.23333236]\n",
      "  [0.67014638 0.17372643]\n",
      "  [0.66856247 0.08408242]]\n",
      "\n",
      " [[0.57038647 0.84089233]\n",
      "  [0.63115448 0.82743614]\n",
      "  [0.59174191 0.7313046 ]\n",
      "  [0.65378682 0.67527013]\n",
      "  [0.69289304 0.56802676]\n",
      "  [0.6727119  0.42903367]\n",
      "  [0.7096438  0.32870129]\n",
      "  [0.72972353 0.2318631 ]\n",
      "  [0.76831505 0.14215053]\n",
      "  [0.82621724 0.0941137 ]]\n",
      "\n",
      " [[0.69708356 0.89538716]\n",
      "  [0.71364706 0.86606931]\n",
      "  [0.74180066 0.80577425]\n",
      "  [0.75717161 0.65924176]\n",
      "  [0.77087054 0.59606793]\n",
      "  [0.76318782 0.46942904]\n",
      "  [0.77497443 0.3530579 ]\n",
      "  [0.80985298 0.24247709]\n",
      "  [0.85727793 0.14787455]\n",
      "  [0.88150532 0.10177793]]\n",
      "\n",
      " [[0.74905222 0.92144998]\n",
      "  [0.80856496 0.90142177]\n",
      "  [0.80618675 0.84155857]\n",
      "  [0.83679395 0.79188792]\n",
      "  [0.8084058  0.58981614]\n",
      "  [0.82034009 0.5016422 ]\n",
      "  [0.8477975  0.35004644]\n",
      "  [0.87237256 0.22805507]\n",
      "  [0.9032381  0.16603471]\n",
      "  [0.92337767 0.11105039]]] [[[0.03754541 0.75417621]\n",
      "  [0.06243721 0.70862715]\n",
      "  [0.09151505 0.59479407]\n",
      "  [0.13316265 0.54653364]\n",
      "  [0.13951154 0.49315309]\n",
      "  [0.18195957 0.41418339]\n",
      "  [0.15103886 0.35789744]\n",
      "  [0.13525367 0.30800238]\n",
      "  [0.13368453 0.27206507]\n",
      "  [0.1034411  0.22077095]]\n",
      "\n",
      " [[0.06795013 0.81370199]\n",
      "  [0.06586271 0.7241955 ]\n",
      "  [0.11192073 0.66532842]\n",
      "  [0.15738638 0.57003077]\n",
      "  [0.22605298 0.50709606]\n",
      "  [0.20728046 0.43193992]\n",
      "  [0.25557086 0.36616791]\n",
      "  [0.18262342 0.28846613]\n",
      "  [0.14850224 0.2112611 ]\n",
      "  [0.13400217 0.18250384]]\n",
      "\n",
      " [[0.12506835 0.83333662]\n",
      "  [0.12108477 0.78646578]\n",
      "  [0.18720945 0.63083588]\n",
      "  [0.2603896  0.56811517]\n",
      "  [0.30120969 0.50363199]\n",
      "  [0.35540615 0.42206597]\n",
      "  [0.35840022 0.32758918]\n",
      "  [0.31639241 0.25682901]\n",
      "  [0.21422673 0.15694134]\n",
      "  [0.20756642 0.10922378]]\n",
      "\n",
      " [[0.17445615 0.8279782 ]\n",
      "  [0.25113351 0.76362549]\n",
      "  [0.28008676 0.65214336]\n",
      "  [0.35052004 0.56677479]\n",
      "  [0.37779209 0.46339596]\n",
      "  [0.43920733 0.40506416]\n",
      "  [0.42303317 0.33690224]\n",
      "  [0.38709743 0.27101099]\n",
      "  [0.34722475 0.17307241]\n",
      "  [0.26875508 0.07923619]]\n",
      "\n",
      " [[0.27555643 0.81103714]\n",
      "  [0.26499495 0.77590467]\n",
      "  [0.38345262 0.68410846]\n",
      "  [0.4118293  0.56269059]\n",
      "  [0.47654674 0.4813837 ]\n",
      "  [0.46959579 0.38507089]\n",
      "  [0.48116918 0.34966386]\n",
      "  [0.44665508 0.25559479]\n",
      "  [0.39287743 0.16866086]\n",
      "  [0.34058692 0.0982758 ]]\n",
      "\n",
      " [[0.34556099 0.82415608]\n",
      "  [0.42188797 0.73463214]\n",
      "  [0.48565068 0.66507535]\n",
      "  [0.51074232 0.58568979]\n",
      "  [0.53657713 0.49752157]\n",
      "  [0.56804135 0.42760508]\n",
      "  [0.51859825 0.33624823]\n",
      "  [0.55271073 0.28114338]\n",
      "  [0.48413777 0.15442586]\n",
      "  [0.49572677 0.04793499]]\n",
      "\n",
      " [[0.45965789 0.80277855]\n",
      "  [0.53972699 0.75902565]\n",
      "  [0.53690826 0.68966798]\n",
      "  [0.58295309 0.63801983]\n",
      "  [0.59264252 0.51995135]\n",
      "  [0.6210837  0.43701516]\n",
      "  [0.62348458 0.34811845]\n",
      "  [0.62941075 0.23333236]\n",
      "  [0.67014638 0.17372643]\n",
      "  [0.66856247 0.08408242]]\n",
      "\n",
      " [[0.57038647 0.84089233]\n",
      "  [0.63115448 0.82743614]\n",
      "  [0.59174191 0.7313046 ]\n",
      "  [0.65378682 0.67527013]\n",
      "  [0.69289304 0.56802676]\n",
      "  [0.6727119  0.42903367]\n",
      "  [0.7096438  0.32870129]\n",
      "  [0.72972353 0.2318631 ]\n",
      "  [0.76831505 0.14215053]\n",
      "  [0.82621724 0.0941137 ]]\n",
      "\n",
      " [[0.69708356 0.89538716]\n",
      "  [0.71364706 0.86606931]\n",
      "  [0.74180066 0.80577425]\n",
      "  [0.75717161 0.65924176]\n",
      "  [0.77087054 0.59606793]\n",
      "  [0.76318782 0.46942904]\n",
      "  [0.77497443 0.3530579 ]\n",
      "  [0.80985298 0.24247709]\n",
      "  [0.85727793 0.14787455]\n",
      "  [0.88150532 0.10177793]]\n",
      "\n",
      " [[0.74905222 0.92144998]\n",
      "  [0.80856496 0.90142177]\n",
      "  [0.80618675 0.84155857]\n",
      "  [0.83679395 0.79188792]\n",
      "  [0.8084058  0.58981614]\n",
      "  [0.82034009 0.5016422 ]\n",
      "  [0.8477975  0.35004644]\n",
      "  [0.87237256 0.22805507]\n",
      "  [0.9032381  0.16603471]\n",
      "  [0.92337767 0.11105039]]]\n"
     ]
    }
   ],
   "source": [
    "# Simple 2D data (e.g. clusters)\n",
    "data = np.random.rand(100, 2)  # 100 2D points between 0 and 1\n",
    "\n",
    "grid_size = (10, 10)\n",
    "som_weights = np.random.rand(grid_size[0], grid_size[1], 2)  # (10x10 grid with 2D weight vectors)\n",
    "\n",
    "def train_som(data, weights, num_epochs=100, learning_rate=0.1, radius=2):\n",
    "    grid_x, grid_y, input_dim = weights.shape\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for input_vector in data:\n",
    "            # 1. Find Best Matching Unit (BMU)\n",
    "            diff = weights - input_vector\n",
    "            dist = np.linalg.norm(diff, axis=2)\n",
    "            bmu_idx = np.unravel_index(np.argmin(dist), (grid_x, grid_y))\n",
    "            \n",
    "            # 2. Update BMU and its neighbors\n",
    "            for i in range(grid_x):\n",
    "                for j in range(grid_y):\n",
    "                    # Compute neighborhood function (Gaussian)\n",
    "                    distance_to_bmu = np.linalg.norm(np.array([i, j]) - np.array(bmu_idx))\n",
    "                    if distance_to_bmu <= radius:\n",
    "                        influence = np.exp(-distance_to_bmu**2 / (2 * (radius**2)))\n",
    "                        weights[i, j] += learning_rate * influence * (input_vector - weights[i, j])\n",
    "    return weights\n",
    "\n",
    "trained_weights = train_som(data, som_weights)\n",
    "\n",
    "# Plot input data\n",
    "plt.scatter(data[:, 0], data[:, 1], c='gray', label='Data')\n",
    "\n",
    "# Plot neuron weights\n",
    "for i in range(grid_size[0]):\n",
    "    for j in range(grid_size[1]):\n",
    "        w = trained_weights[i, j]\n",
    "        plt.plot(w[0], w[1], 'ro')  # plot neuron\n",
    "plt.title(\"SOM Mapping\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93319c4-505a-42f5-b2a8-2ac1546df22b",
   "metadata": {},
   "source": [
    "## Experiment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "827f89a5-f19b-424c-aa69-2193cab133c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoders:  0.8521993796328488\n",
      "PCA:  0.30546557481665276\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def circle(r, θ):\n",
    "    x = r * np.cos(θ)\n",
    "    y = r * np.sin(θ)\n",
    "    return x, y\n",
    "\n",
    "def data_generated():\n",
    "    train = []\n",
    "    for i in range(1000):\n",
    "        θ = np.random.uniform(0, 2*np.pi)\n",
    "        r = np.random.randn()\n",
    "        x, y = (circle(r, θ))\n",
    "        train.append([x, y])\n",
    "    return np.array(train)\n",
    "\n",
    "def PCA_train(train):\n",
    "    scale = StandardScaler()\n",
    "    scaled_train = scale.fit_transform(train)\n",
    "    pca = PCA(n_components=1)\n",
    "    train_pca = pca.fit_transform(scaled_train)\n",
    "    inversed = pca.inverse_transform(train_pca)\n",
    "\n",
    "    mse = ((train - inversed) ** 2).mean(axis=None)\n",
    "    return mse\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def encoder(data, weights, bias):\n",
    "    return tanh(np.dot(data, weights) + bias)\n",
    "\n",
    "def decoder(data, weights, bias):\n",
    "    return tanh(np.dot(data, weights) + bias)\n",
    "\n",
    "def autoencoders(encoder, decoder, data):\n",
    "    input_dim = data.shape[1]\n",
    "    latent_dim = 1\n",
    "    \n",
    "    weight_encoder = np.random.randn(input_dim, latent_dim)\n",
    "    bias_encoder = np.random.randn(latent_dim)\n",
    "    weight_decoder = np.random.randn(latent_dim, input_dim)\n",
    "    bias_decoder = np.random.randn(input_dim)\n",
    "\n",
    "    z1 = encoder(data, weight_encoder, bias_encoder)\n",
    "    z2 = decoder(z1, weight_decoder, bias_decoder)\n",
    "\n",
    "    mse = ((data - z2)** 2).mean()\n",
    "    return mse\n",
    "\n",
    "train = data_generated()\n",
    "\n",
    "ae = autoencoders(encoder, decoder, train)\n",
    "pca = PCA_train(train)\n",
    "\n",
    "print(\"Autoencoders: \", ae)\n",
    "print(\"PCA: \", pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dfa8ec-aed3-4bf0-a8a2-e9097fbb4d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
